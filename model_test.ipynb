{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import tsc_utils as tu\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv3_k': 5, 'model_name': 'sermanet_v2', 'conv3_p': 0.7, 'conv2_d': 128, 'conv1_d': 64, 'conv3_d': 256, 'fc4_size': 2048, 'conv1_k': 5, 'conv2_k': 5, 'conv2_p': 0.8, 'num_classes': 43, 'fc4_p': 0.5, 'conv1_p': 0.9}\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = tu.lenet\n",
    "    model_params = tu.params_orig_lenet\n",
    "    \n",
    "    model = tu.lenet\n",
    "    model_params = tu.params_big_lenet\n",
    "\n",
    "    model = tu.lenet\n",
    "    model_params = tu.params_huge_lenet\n",
    "    \n",
    "    model = tu.sermanet\n",
    "    model_params = tu.params_sermanet\n",
    "    \n",
    "    model = tu.sermanet\n",
    "    model_params = tu.params_sermanet_big\n",
    "    \n",
    "    model = tu.sermanet_v2\n",
    "    model_params = tu.params_sermanet_v2\n",
    "    \n",
    "    model = tu.sermanet_v2\n",
    "    model_params = tu.params_sermanet_v2_big\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "    y = tf.placeholder(tf.int32, (None))\n",
    "    one_hot_y = tf.one_hot(y, model_params['num_classes'])\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "    logits = model(x, params=model_params, is_training=is_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'conv1/weights:0' shape=(5, 5, 1, 64) dtype=float32_ref>\n",
      "(5, 5, 1, 64)\n",
      "<tf.Variable 'conv1/biases:0' shape=(64,) dtype=float32_ref>\n",
      "(64,)\n",
      "<tf.Variable 'conv2/weights:0' shape=(5, 5, 64, 128) dtype=float32_ref>\n",
      "(5, 5, 64, 128)\n",
      "<tf.Variable 'conv2/biases:0' shape=(128,) dtype=float32_ref>\n",
      "(128,)\n",
      "<tf.Variable 'conv3/weights:0' shape=(5, 5, 128, 256) dtype=float32_ref>\n",
      "(5, 5, 128, 256)\n",
      "<tf.Variable 'conv3/biases:0' shape=(256,) dtype=float32_ref>\n",
      "(256,)\n",
      "<tf.Variable 'fc4/weights:0' shape=(7168, 2048) dtype=float32_ref>\n",
      "(7168, 2048)\n",
      "<tf.Variable 'fc4/biases:0' shape=(2048,) dtype=float32_ref>\n",
      "(2048,)\n",
      "<tf.Variable 'out/weights:0' shape=(2048, 43) dtype=float32_ref>\n",
      "(2048, 43)\n",
      "<tf.Variable 'out/biases:0' shape=(43,) dtype=float32_ref>\n",
      "(43,)\n",
      "15796267\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print(variable)\n",
    "        print(shape)\n",
    "        #print(len(shape))\n",
    "        variable_parametes = 1\n",
    "        for dim in shape:\n",
    "            #print(dim)\n",
    "            variable_parametes *= dim.value\n",
    "        #print(variable_parametes)\n",
    "        total_parameters += variable_parametes\n",
    "    print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "# original set\n",
    "train_fname = 'data/train_preprocessed.p'\n",
    "valid_fname = 'data/valid_preprocessed.p'\n",
    "\n",
    "# augmented set with smaller variations\n",
    "train_fname_FA_fine = 'data/train_flip_extended_augmented_0.7_preprocessed.p'\n",
    "valid_fname_FA_fine = 'data/valid_flip_extended_augmented_0.7_preprocessed.p'\n",
    "\n",
    "# augmented set\n",
    "train_fname_FA = 'data/train_flip_extended_augmented_preprocessed.p'\n",
    "valid_fname_FA = 'data/valid_flip_extended_augmented_preprocessed.p'\n",
    "\n",
    "# flip extended set\n",
    "train_fname_F = 'data/train_flip_extended_preprocessed.p'\n",
    "valid_fname_F = 'data/valid_flip_extended_preprocessed.p'\n",
    "\n",
    "\n",
    "test_fname = 'data/test_preprocessed.p'\n",
    "\n",
    "def data_loader(train_file, valid_file, test_file):\n",
    "    X_train, y_train = tu.load_pickled_data(train_file, columns = ['features', 'labels'])\n",
    "    X_valid, y_valid = tu.load_pickled_data(valid_file, columns = ['features', 'labels'])\n",
    "    X_test, y_test = tu.load_pickled_data(test_file, columns = ['features', 'labels'])\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_valid.shape, y_valid.shape)\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    return (X_train, y_train, X_valid, y_valid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34799, 32, 32, 1) (34799,)\n",
      "(4410, 32, 32, 1) (4410,)\n",
      "(12630, 32, 32, 1) (12630,)\n"
     ]
    }
   ],
   "source": [
    "data_set0 = data_loader(train_fname, valid_fname, test_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= train_model() arguments: ==========\n",
      "resuming = False\n",
      "model = <function lenet at 0x00000247D1670E18>\n",
      "model_params = {'batch_norm': True, 'conv2_p': 1, 'model_name': 'lenet', 'fc3_p': 1, 'conv1_d': 6, 'num_classes': 43, 'conv1_k': 5, 'conv2_k': 5, 'conv2_d': 16, 'fc3_size': 120, 'fc4_size': 84, 'fc4_p': 1, 'conv1_p': 1}\n",
      "learning_rate = 0.001\n",
      "max_epochs = 1001\n",
      "batch_size = 256\n",
      "early_stopping_enabled = True\n",
      "early_stopping_patience = 10\n",
      "log_epoch = 1\n",
      "print_epoch = 1\n",
      "top_k = 5\n",
      "return_top_k = False\n",
      "plot_featuremap = False\n",
      "=============================================\n",
      "BN_lenet__conv1_d_6_conv1_k_5_conv1_p_1_conv2_d_16_conv2_k_5_conv2_p_1_fc3_p_1_fc3_size_120_fc4_p_1_fc4_size_84\n",
      "a8045a95509b7c74\n",
      "model dir: C:\\Users\\dingran\\github\\CarND-Traffic-Sign-Classifier-Project\\models\\a8045a95509b7c74\n",
      "{'batch_norm': True, 'conv2_p': 1, 'model_name': 'lenet', 'fc3_p': 1, 'conv1_d': 6, 'num_classes': 43, 'conv1_k': 5, 'conv2_k': 5, 'conv2_d': 16, 'fc3_size': 120, 'fc4_size': 84, 'fc4_p': 1, 'conv1_p': 1}\n",
      "lenet pool2 reshaped size:  [None, 1024]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-29eb4ca0eb63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresuming\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdata_set0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\github\\CarND-Traffic-Sign-Classifier-Project\\tsc_utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, X_valid, y_valid, X_test, y_test, resuming, model, model_params, learning_rate, max_epochs, batch_size, early_stopping_enabled, early_stopping_patience, log_epoch, print_epoch, top_k, return_top_k, plot_featuremap)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0moutput_top_k\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dingran\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dingran\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dingran\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mc:\\users\\dingran\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dingran\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tu.lenet\n",
    "params = tu.params_orig_lenet\n",
    "params['batch_norm'] = True\n",
    "params['conv1_p'] = 1\n",
    "params['conv2_p'] = 1\n",
    "params['fc3_p'] = 1\n",
    "params['fc4_p'] = 1\n",
    "config = dict(model=model, model_params=params, resuming=False)\n",
    "\n",
    "_ = tu.train_model(*data_set0, **config, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
